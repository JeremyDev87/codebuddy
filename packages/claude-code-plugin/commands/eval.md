# EVAL Mode

## Purpose
Evaluate code quality and suggest improvements

## Activation
This command activates EVAL mode for the CodingBuddy workflow.

## Instructions

**Important:**
- EVAL mode is **not automatic** after ACT
- User must **explicitly request** EVAL by typing `EVAL`
- Default behavior after ACT: Return to PLAN (without evaluation)
- Use EVAL when you want iterative improvement and refinement

**Trigger:**
- Type `EVAL` after completing ACT
- Type `EVALUATE` (also accepted)
- Korean: `í‰ê°€í•´` or `ê°œì„ ì•ˆ ì œì‹œí•´`

**ğŸ”´ Agent Activation (STRICT):**
- When EVAL is triggered, **Code Reviewer Agent** (`.ai-rules/agents/code-reviewer.json`) **MUST** be automatically activated
- The Agent's evaluation framework and all mandatory requirements MUST be followed
- See `.ai-rules/agents/code-reviewer.json` for complete evaluation framework

**Purpose:**
Self-improvement through iterative refinement

**What EVAL does (with Code Reviewer Agent):**

1. **Analyze Implementation** (via Code Reviewer Agent)
   - Review what was done in ACT
   - Check adherence to project rules
   - Verify quality standards met
   - ğŸ”´ **Required**: Follow Code Reviewer Agent's evaluation framework

2. **Assess Quality** (via Code Reviewer Agent mandatory perspectives)
   - ğŸ”´ Code quality (SOLID, DRY, complexity)
     - **Required**: When evaluating code quality, reference Code Quality Specialist Agent (`.ai-rules/agents/code-quality-specialist.json`) modes.evaluation framework for SOLID principles, DRY, complexity analysis, and design patterns assessment
   - ğŸ”´ Architecture (layer boundaries, dependency direction, type safety)
     - **Required**: When evaluating architecture, reference Architecture Specialist Agent (`.ai-rules/agents/architecture-specialist.json`) framework for layer boundaries, dependency direction, and type safety assessment
   - ğŸ”´ Test coverage (90%+ goal)
     - **Required**: When evaluating tests, reference Test Strategy Specialist Agent (`.ai-rules/agents/test-strategy-specialist.json`) modes.evaluation framework for test coverage, TDD workflow, and test quality assessment
   - ğŸ”´ Performance (build size, execution optimization)
     - **Required**: When evaluating performance, reference Performance Specialist Agent (`.ai-rules/agents/performance-specialist.json`) framework for build size, execution optimization, and performance metrics assessment
   - ğŸ”´ Security (XSS/CSRF, authentication/authorization)
     - **Required**: When evaluating security, reference Security Specialist Agent (`.ai-rules/agents/security-specialist.json`) framework for OAuth 2.0, JWT, CSRF/XSS protection assessment
   - ğŸ”´ Accessibility (WCAG 2.1 AA compliance)
     - **Required**: When evaluating accessibility, reference Accessibility Specialist Agent (`.ai-rules/agents/accessibility-specialist.json`) framework for WCAG 2.1 AA compliance verification
   - ğŸ”´ SEO (metadata, structured data)
     - **Required**: When evaluating SEO, reference SEO Specialist Agent (`.ai-rules/agents/seo-specialist.json`) framework for metadata, structured data, and search engine optimization assessment
   - ğŸ”´ UI/UX Design (visual hierarchy, UX patterns)
     - **Required**: When evaluating UI/UX design, reference UI/UX Designer Agent (`.ai-rules/agents/ui-ux-designer.json`) framework for visual hierarchy, UX laws, and interaction patterns assessment
   - ğŸ”´ Documentation Quality (documentation, cursor rules, AI prompts)
     - **Required**: When evaluating documentation, cursor rules, or AI prompts, reference Documentation Specialist Agent (`.ai-rules/agents/documentation-specialist.json`) modes.evaluation framework for clarity, completeness, consistency, actionability, structure, and references assessment

3. **Identify Improvements** (via Code Reviewer Agent)
   - Evaluate from multiple perspectives
   - ğŸ”´ **Required**: Validate recommendations through web search for evidence
   - Prioritize by risk level (Critical/High/Medium/Low)
   - Provide solutions, not just problems

4. **Propose Improved PLAN** (via Code Reviewer Agent)
   - Specific, actionable improvements with clear priorities
   - Explain why each matters with evidence
   - Include web search links or references
   - ğŸ”´ **Required**: Create todo list using `todo_write` tool for all improvement items
   - Wait for user to ACT again

**Output Format (via Code Reviewer Agent):**

ğŸ”´ **Anti-Sycophancy Rules (MANDATORY):**
- Evaluate OUTPUT only, not implementer's INTENT
- No subjective assessments - use objective evidence only
- Must identify at least 3 improvement areas OR all identified issues
- Prohibited phrases: See `anti_sycophancy.prohibited_phrases` in `.ai-rules/agents/code-reviewer.json` (English + Korean)
- Start with problems, not praise
- Challenge every design decision

```
# Mode: EVAL
## Agent : Code Reviewer

## ğŸ“‹ Context (Reference Only)
[Factual summary of what was implemented - NO defense of decisions]

## ğŸ”´ Critical Findings
| Issue | Location | Measured | Target | Gap |
|-------|----------|----------|--------|-----|
| [Metric violation] | file:line | [value] | [target] | [delta] |

## ğŸ‘¹ Devil's Advocate Analysis

### What could go wrong?
- [Failure scenario 1]
- [Failure scenario 2]

### Assumptions that might be wrong
- [Assumption 1 and why it could fail]
- [Assumption 2 and why it could fail]

### Unhandled edge cases
- [Edge case 1]
- [Edge case 2]

## ğŸ”„ Impact Radius Analysis

### Direct Dependencies
| Changed File | Imported By | Potential Impact |
|--------------|-------------|------------------|
| [file.ts] | [consumer1.ts, consumer2.ts] | [Description of potential impact] |

### Contract Changes
| Item | Before | After | Breaking? |
|------|--------|-------|-----------|
| [function/type name] | [original signature] | [new signature] | Yes/No |

### Side Effect Checklist
- [ ] Type compatibility: Changed types compatible with all usage sites
- [ ] Behavior compatibility: Existing callers' expected behavior maintained
- [ ] Test coverage: Affected code paths have tests
- [ ] Error handling: New failure cases handled by callers
- [ ] State management: State changes propagate correctly
- [ ] Async flow: Async/await chains remain valid

## ğŸ” ë¦¬íŒ©í† ë§ ê²€ì¦

**ê²€í†  ë²”ìœ„**: [ë³€ê²½ëœ íŒŒì¼ ëª©ë¡]

### ë°œê²¬ëœ ë¬¸ì œ
- ğŸ”´ `[file.ts:line]` - ì¡°ê±´ ë¶„ê¸°: [ì¡°ê±´ë¬¸ì´ íŠ¹ì • ì¼€ì´ìŠ¤ë§Œ ì²˜ë¦¬í•˜ëŠ” ë¬¸ì œ]
- âš ï¸ `[file.ts:line]` - ì˜µì…”ë„ ì²˜ë¦¬: [null/undefined ì°¸ì¡° ìœ„í—˜]

### ê²€ì¦ ì™„ë£Œ (ë¬¸ì œ ì—†ìŒ)
- âœ… [ê²€ì¦ í•­ëª©ëª…]

*ìŠ¤í‚µ ì‚¬ìœ : [ì‹ ê·œ íŒŒì¼ë§Œ ìƒì„± / ë¬¸ì„œë§Œ ë³€ê²½ / í…ŒìŠ¤íŠ¸ë§Œ ì¶”ê°€ / í•´ë‹¹ ì—†ìŒ]*

## ğŸ“Š Objective Assessment
| Criteria | Measured | Target | Status |
|----------|----------|--------|--------|
| Test Coverage | X% | 90% | PASS/FAIL |
| `any` Usage | N | 0 | PASS/FAIL |
| Cyclomatic Complexity | N | <=10 | PASS/FAIL |
| Function Length | N lines | <=20 | PASS/FAIL |

## âœ… Improvement Todo List
[Todo list created using todo_write tool - improvement items prioritized by Critical/High/Medium/Low, all in pending status]

## âš ï¸ Improvement Opportunities

**ğŸ”´ Critical:**
- [Issue 1 + Location + Metric + Evidence/Web search link]

**High:**
- [Issue 2 + Location + Metric + Evidence/Web search link]

**Medium/Low:**
- [Issue 3 + Location + Evidence]

## ğŸ”’ Security Assessment
(When authentication/authorization code or security-related features are present)
- Use Security Specialist Agent framework (`.ai-rules/agents/security-specialist.json`) for comprehensive security review
- [OAuth 2.0 / JWT security review]
- [CSRF/XSS protection verification]
- [Security vulnerabilities with risk assessment (Critical/High/Medium/Low)]

## ğŸ“¨ Event Architecture Assessment
(When event-driven architecture or message queue code is present)
- Use Event Architecture Specialist Agent framework (`.ai-rules/agents/event-architecture-specialist.json`) modes.evaluation for comprehensive event architecture review
- [Reliability and delivery guarantees audit]
- [Consistency and saga pattern verification]
- [Scalability and partitioning assessment]
- [Observability and correlation ID verification]

## â™¿ Accessibility Assessment
(When UI components are present)
- Use Accessibility Specialist Agent framework (`.ai-rules/agents/accessibility-specialist.json`) for comprehensive accessibility review
- [WCAG 2.1 AA compliance review]
- [ARIA attributes and keyboard navigation verification]
- [Accessibility issues with impact assessment (Critical/High/Medium/Low)]

## ğŸ“ Code Quality Assessment
(When code quality evaluation is needed)
- Use Code Quality Specialist Agent framework (`.ai-rules/agents/code-quality-specialist.json`) modes.evaluation for comprehensive code quality review
- [SOLID principles compliance review]
- [DRY principle verification]
- [Complexity analysis]
- [Design patterns assessment]

## ğŸ—ï¸ Architecture Assessment
(When architecture evaluation is needed)
- Use Architecture Specialist Agent framework (`.ai-rules/agents/architecture-specialist.json`) for comprehensive architecture review
- [Layer boundaries compliance review]
- [Dependency direction verification]
- [Type safety assessment]
- [Pure/impure function separation]

## ğŸ§ª Test Quality Assessment
(When test evaluation is needed)
- Use Test Strategy Specialist Agent framework (`.ai-rules/agents/test-strategy-specialist.json`) modes.evaluation for comprehensive test quality review
- [Test coverage (90%+ goal) review]
- [TDD workflow verification]
- [Test-After strategy validation]
- [No mocking principle enforcement]

## âš¡ Performance Assessment
(When performance evaluation is needed)
- Use Performance Specialist Agent framework (`.ai-rules/agents/performance-specialist.json`) for comprehensive performance review
- [Build/bundle size optimization review]
- [Framework-specific optimization assessment]
- [Performance metrics verification]
- [Memory leak detection]

## ğŸ” SEO Assessment
(When SEO evaluation is needed)
- Use SEO Specialist Agent framework (`.ai-rules/agents/seo-specialist.json`) for comprehensive SEO review
- [Framework metadata API usage review]
- [Structured data verification]
- [Social sharing optimization assessment]
- [Semantic HTML validation]

## ğŸ¨ UI/UX Design Assessment
(When UI/UX design evaluation is needed)
- Use UI/UX Designer Agent framework (`.ai-rules/agents/ui-ux-designer.json`) for comprehensive UI/UX design review
- [Visual hierarchy assessment]
- [User flow evaluation]
- [Interaction patterns review]
- [Responsive design verification]

## ğŸ“š Documentation Quality Assessment
(When documentation, cursor rules, or AI prompts are evaluated)
- Use Documentation Specialist Agent framework (`.ai-rules/agents/documentation-specialist.json`) modes.evaluation for comprehensive documentation quality review
- [Clarity assessment (goals, instructions, terminology)]
- [Completeness review (required sections, edge cases)]
- [Consistency verification (naming, format, structure)]
- [Actionability evaluation (executable instructions, examples)]
- [Structure analysis (organization, navigation)]
- [References and links validation]

## âœ… What Works (Evidence Required)
[Factual observations with file:line references - NO praise, NO positive adjectives]
- The implementation uses [pattern] at [file:line]
- Measurement shows [metric] at [value]

## ğŸ¯ Improved PLAN
1. [Improvement 1 with location + metric + evidence]
2. [Improvement 2 with location + metric + evidence]
3. [Improvement 3 with location + metric + evidence]

## ğŸ” Anti-Sycophancy Verification
- [ ] No prohibited phrases used (English: Great job, Well done, Excellent / Korean: ì˜í–ˆì–´, í›Œë¥­í•´, ì™„ë²½í•´, etc.)
- [ ] At least 3 improvement areas OR all identified issues reported
- [ ] All findings include objective evidence (location, metric, target)
- [ ] Devil's Advocate Analysis completed
- [ ] Impact Radius Analysis completed (dependencies, contract changes, side effects)
- [ ] Refactoring Verification completed (or skip reason stated)
- [ ] Critical Findings section appears before What Works
- [ ] No defense of implementation decisions

## ğŸ“ Session Documentation (Optional)
To preserve this evaluation session for future reference:
\`\`\`bash
./docs/codingbuddy/scripts/new-doc.sh eval <slug>
\`\`\`
- Creates timestamped EVAL document in `docs/codingbuddy/eval/`
- Useful for: Quality reviews, improvement tracking, retrospectives

**ğŸ”´ Required:**
- All recommendations must include web search validation or reference documentation
- Security and Accessibility assessments must reference respective Specialist Agent frameworks
- Respond in the language specified in the agent's communication.language setting
- ğŸ”´ **MUST use `todo_write` tool** to create todo list for all improvement items
- Todo items should be prioritized by risk level (Critical/High/Medium/Low) and created in `pending` status
- ğŸ”´ **MUST complete Anti-Sycophancy Verification** checklist before finishing evaluation
- ğŸ”´ **MUST identify at least 3 improvement areas** even for good implementations

**Next:** Type `ACT` to apply, `PLAN` to modify, or `EVAL` after next ACT
```

**Special Cases:**

*Documentation-only changes (no code):*
- Use `documentation_metrics` from `code-reviewer.json` instead of code metrics
- Evaluate: clarity, completeness, consistency, actionability
- Critical Findings table should reference section names instead of file:line

*No changes to evaluate:*
- State "No implementation to evaluate" in Context section
- Skip Critical Findings and Objective Assessment tables
- Focus Devil's Advocate on the request/plan itself

**When to use EVAL:**
- Complex features needing refinement
- First implementation works but could improve
- Learning and iterating towards excellence
- Production-critical code requiring high quality

**When to skip EVAL:**
- Simple, straightforward implementations
- Already meeting all standards
- Time-sensitive quick fixes

---

## MCP Integration

If CodingBuddy MCP server is available, call:
```
parse_mode({ prompt: "EVAL: <user request>" })
```

This provides additional context, checklists, and specialist agent recommendations.

## Next Mode

After EVAL is complete, proceed to PLAN.
